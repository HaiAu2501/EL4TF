{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025329c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().resolve().parent))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from preprocess import VN30, TARGETS, preprocess_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866d3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'ACB'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0617f4",
   "metadata": {},
   "source": [
    "# Bước 1: Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2c56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: torch.Size([1094, 30, 4]), torch.Size([1094, 4])\n",
      "Valid shape: torch.Size([121, 30, 4]), torch.Size([121, 4])\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader, scaler = preprocess_v2(symbol, 'rnn', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f53b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)          # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))  # (max_len, 1, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (seq_len, batch, d_model)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        model_dim: int = 64,\n",
    "        num_heads: int = 4,\n",
    "        num_layers: int = 2,\n",
    "        dim_feedforward: int = 128,\n",
    "        dropout: float = 0.1,\n",
    "        seq_len: int = 30\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # project input features → model_dim\n",
    "        self.input_proj = nn.Linear(input_dim, model_dim)\n",
    "        # positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(model_dim, max_len=seq_len)\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=False    # we’ll feed (seq_len, batch, model_dim)\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # final regression head\n",
    "        self.output_layer = nn.Linear(model_dim, input_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_dim)\n",
    "        returns: (batch, input_dim)\n",
    "        \"\"\"\n",
    "        # → (batch, seq_len, model_dim)\n",
    "        x = self.input_proj(x)\n",
    "        # prepare for Transformer: (seq_len, batch, model_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # add positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "        # run through encoder\n",
    "        x = self.transformer(x)           # (seq_len, batch, model_dim)\n",
    "        # take the last time step’s output\n",
    "        last = x[-1, :, :]               # (batch, model_dim)\n",
    "        # project back to our 4‐dim target\n",
    "        return self.output_layer(last)   # (batch, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7dd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    input_dim=4,      # 4 features: open, high, low, close\n",
    "    model_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    dropout=0.1,\n",
    "    seq_len=30\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "criterion = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b26c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10/200: Train Loss = 0.002818, Valid Loss = 0.001041, Best Val Loss = 0.000935, LR = 0.000800\n",
      "Epoch  20/200: Train Loss = 0.001766, Valid Loss = 0.000773, Best Val Loss = 0.000773, LR = 0.000640\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m X_batch, y_batch = X_batch, y_batch\n\u001b[32m     10\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m loss  = criterion(preds, y_batch)\n\u001b[32m     13\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khang\\anaconda3\\envs\\trash_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khang\\anaconda3\\envs\\trash_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     53\u001b[39m x = x.permute(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# add positional encoding\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# run through encoder\u001b[39;00m\n\u001b[32m     57\u001b[39m x = \u001b[38;5;28mself\u001b[39m.transformer(x)           \u001b[38;5;66;03m# (seq_len, batch, model_dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khang\\anaconda3\\envs\\trash_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khang\\anaconda3\\envs\\trash_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch, y_batch\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_batch)\n",
    "        loss  = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # --- validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in valid_loader:\n",
    "            X_batch, y_batch = X_batch, y_batch\n",
    "            preds = model(X_batch)\n",
    "            val_loss += criterion(preds, y_batch).item() * X_batch.size(0)\n",
    "    val_loss /= len(valid_loader.dataset)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # --- checkpoint ---\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'checkpoints/tft_{symbol}.pth')\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == n_epochs:\n",
    "        print(f\"Epoch {epoch:3d}/{n_epochs}: \"\n",
    "              f\"Train Loss = {train_loss:.6f}, \"\n",
    "              f\"Valid Loss = {val_loss:.6f}, \"\n",
    "              f\"Best Val Loss = {best_val_loss:.6f}, \"\n",
    "\t\t\t  f\"LR = {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a2fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R²: -5.3838\n",
      "Test MAPE: 10.2729%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'checkpoints/tft_{symbol}.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Thu thập dự đoán và nhãn\n",
    "all_preds   = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch\n",
    "        preds = model(X_batch).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(y_batch.numpy())\n",
    "\n",
    "all_preds   = np.vstack(all_preds)   # (n_samples, 5)\n",
    "all_targets = np.vstack(all_targets)\n",
    "\n",
    "# Inverse scaling\n",
    "all_preds_inv   = scaler.inverse_transform(all_preds)\n",
    "all_targets_inv = scaler.inverse_transform(all_targets)\n",
    "\n",
    "# Tính metrics\n",
    "r2   = r2_score(all_targets_inv, all_preds_inv, multioutput='uniform_average')\n",
    "mape = mean_absolute_percentage_error(all_targets_inv, all_preds_inv) * 100\n",
    "\n",
    "print(f\"Test R²: {r2:.4f}\")\n",
    "print(f\"Test MAPE: {mape:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trash_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
