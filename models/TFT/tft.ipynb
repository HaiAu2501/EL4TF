{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025329c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().resolve().parent))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from preprocess import VN30, TARGETS, preprocess_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866d3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'ACB'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0617f4",
   "metadata": {},
   "source": [
    "# Bước 1: Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2c56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: torch.Size([1094, 30, 4]), torch.Size([1094, 4])\n",
      "Valid shape: torch.Size([121, 30, 4]), torch.Size([121, 4])\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader, scaler = preprocess_v2(symbol, 'rnn', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f53b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)          # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))  # (max_len, 1, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (seq_len, batch, d_model)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        model_dim: int = 64,\n",
    "        num_heads: int = 4,\n",
    "        num_layers: int = 2,\n",
    "        dim_feedforward: int = 128,\n",
    "        dropout: float = 0.1,\n",
    "        seq_len: int = 30\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # project input features → model_dim\n",
    "        self.input_proj = nn.Linear(input_dim, model_dim)\n",
    "        # positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(model_dim, max_len=seq_len)\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=False    # we’ll feed (seq_len, batch, model_dim)\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # final regression head\n",
    "        self.output_layer = nn.Linear(model_dim, input_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_dim)\n",
    "        returns: (batch, input_dim)\n",
    "        \"\"\"\n",
    "        # → (batch, seq_len, model_dim)\n",
    "        x = self.input_proj(x)\n",
    "        # prepare for Transformer: (seq_len, batch, model_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # add positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "        # run through encoder\n",
    "        x = self.transformer(x)           # (seq_len, batch, model_dim)\n",
    "        # take the last time step’s output\n",
    "        last = x[-1, :, :]               # (batch, model_dim)\n",
    "        # project back to our 4‐dim target\n",
    "        return self.output_layer(last)   # (batch, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7dd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    input_dim=4,      # 4 features: open, high, low, close\n",
    "    model_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    dropout=0.1,\n",
    "    seq_len=30\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "criterion = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b26c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10/200: Train Loss = 0.003191, Valid Loss = 0.003000, Best Val Loss = 0.001134, LR = 0.000800\n",
      "Epoch  20/200: Train Loss = 0.001885, Valid Loss = 0.000633, Best Val Loss = 0.000633, LR = 0.000640\n",
      "Epoch  30/200: Train Loss = 0.001823, Valid Loss = 0.000721, Best Val Loss = 0.000614, LR = 0.000512\n",
      "Epoch  40/200: Train Loss = 0.001551, Valid Loss = 0.000748, Best Val Loss = 0.000614, LR = 0.000410\n",
      "Epoch  50/200: Train Loss = 0.001390, Valid Loss = 0.000748, Best Val Loss = 0.000614, LR = 0.000328\n",
      "Epoch  60/200: Train Loss = 0.001176, Valid Loss = 0.000671, Best Val Loss = 0.000614, LR = 0.000262\n",
      "Epoch  70/200: Train Loss = 0.001237, Valid Loss = 0.000635, Best Val Loss = 0.000614, LR = 0.000210\n",
      "Epoch  80/200: Train Loss = 0.001214, Valid Loss = 0.000681, Best Val Loss = 0.000614, LR = 0.000168\n",
      "Epoch  90/200: Train Loss = 0.001107, Valid Loss = 0.000624, Best Val Loss = 0.000614, LR = 0.000134\n",
      "Epoch 100/200: Train Loss = 0.001076, Valid Loss = 0.000642, Best Val Loss = 0.000614, LR = 0.000107\n",
      "Epoch 110/200: Train Loss = 0.001070, Valid Loss = 0.000672, Best Val Loss = 0.000614, LR = 0.000086\n",
      "Epoch 120/200: Train Loss = 0.001057, Valid Loss = 0.000667, Best Val Loss = 0.000614, LR = 0.000069\n",
      "Epoch 130/200: Train Loss = 0.001031, Valid Loss = 0.000682, Best Val Loss = 0.000614, LR = 0.000055\n",
      "Epoch 140/200: Train Loss = 0.001027, Valid Loss = 0.000671, Best Val Loss = 0.000614, LR = 0.000044\n",
      "Epoch 150/200: Train Loss = 0.001025, Valid Loss = 0.000701, Best Val Loss = 0.000614, LR = 0.000035\n",
      "Epoch 160/200: Train Loss = 0.001009, Valid Loss = 0.000676, Best Val Loss = 0.000614, LR = 0.000028\n",
      "Epoch 170/200: Train Loss = 0.000973, Valid Loss = 0.000655, Best Val Loss = 0.000614, LR = 0.000023\n",
      "Epoch 180/200: Train Loss = 0.000985, Valid Loss = 0.000657, Best Val Loss = 0.000614, LR = 0.000018\n",
      "Epoch 190/200: Train Loss = 0.000989, Valid Loss = 0.000652, Best Val Loss = 0.000614, LR = 0.000014\n",
      "Epoch 200/200: Train Loss = 0.000985, Valid Loss = 0.000653, Best Val Loss = 0.000614, LR = 0.000012\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch, y_batch\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_batch)\n",
    "        loss  = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # --- validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in valid_loader:\n",
    "            X_batch, y_batch = X_batch, y_batch\n",
    "            preds = model(X_batch)\n",
    "            val_loss += criterion(preds, y_batch).item() * X_batch.size(0)\n",
    "    val_loss /= len(valid_loader.dataset)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # --- checkpoint ---\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'checkpoints/tft_{symbol}.pth')\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == n_epochs:\n",
    "        print(f\"Epoch {epoch:3d}/{n_epochs}: \"\n",
    "              f\"Train Loss = {train_loss:.6f}, \"\n",
    "              f\"Valid Loss = {val_loss:.6f}, \"\n",
    "              f\"Best Val Loss = {best_val_loss:.6f}, \"\n",
    "\t\t\t  f\"LR = {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R²: -8.1745\n",
      "Test MAPE: 12.3678%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'checkpoints/tft_{symbol}.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Thu thập dự đoán và nhãn\n",
    "all_preds   = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch\n",
    "        preds = model(X_batch).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(y_batch.numpy())\n",
    "\n",
    "all_preds   = np.vstack(all_preds)   # (n_samples, 5)\n",
    "all_targets = np.vstack(all_targets)\n",
    "\n",
    "# Inverse scaling\n",
    "all_preds_inv   = scaler.inverse_transform(all_preds)\n",
    "all_targets_inv = scaler.inverse_transform(all_targets)\n",
    "\n",
    "# Tính metrics\n",
    "r2   = r2_score(all_targets_inv, all_preds_inv, multioutput='uniform_average')\n",
    "mape = mean_absolute_percentage_error(all_targets_inv, all_preds_inv) * 100\n",
    "\n",
    "print(f\"Test R²: {r2:.4f}\")\n",
    "print(f\"Test MAPE: {mape:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
